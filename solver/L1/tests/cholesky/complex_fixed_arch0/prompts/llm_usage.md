# 大模型辅助使用记录

## 基本信息

- **模型名称**：OpenAI codex，juice 200
- **提供方 / 访问方式**：OpenAI API ([api.openai.com](http://api.openai.com/))
- **使用日期**：2025-10-26
- **项目名称**：Cholesky L1 算子优化

---

## **使用场景 1：性能瓶颈分析**

在开始优化前，我们首先在AI指导下完成了性能瓶颈的分析。这一阶段的主要目标是确保优化方向正确，并为后续优化提供参考基准和对比材料。

### **Prompt设计：**

我正在优化 Vitis 库中的  Cholesky算子。

这是官方 Cholesky 算子的核心代码：

- `// --- 贴上官方原始核心代码 ---*`

这是它未经优化的 HLS 综合报告摘要：

`// --- 基准 HLS 报告中的 P&R---`

**【目标】**

我的优化目标是实现理论上的最高吞吐率，即降低端到端延迟，保持主循环流水线启动间隔（II）为 1。资源消耗是次要考虑因素。

**【诊断问题】**

1. 请解读这份报告。基于代码和报告，**根本原因**是什么导致了性能不佳（ Latency 过高）？
2. 代码中是否存在特定的**数据依赖**（如循环携带依赖）或**存储瓶颈**（如单端口 BRAM 访问冲突）？请指出具体是哪几行代码导致了这些问题。

### **模型输出摘要**

模型准确地解读了HLS报告，并一针见血地指出，基准设计的性能瓶颈主要源于三个方面：1) 核心算术单元延迟高；2) 存储访问模式受限，基于 BRAM 的实现限制了并行读写能力；3) 串行化的计算流程，内外层循环缺乏并行处理机制

### **人工审核与采纳情况**

模型提供的瓶颈分析系统且专业，帮助我构建了初步的优化思路。

---

## **使用场景 2：优化策略制定**

在了解算子优化瓶颈后，我在llm指导下完成了HLS 性能优化策略制定和代码重构方案探索。

### **Prompt设计：**

你好，我们将继续进行一个高层次综合（HLS）优化任务。请你继续扮演一名资深的 FPGA HLS 专家。

核心优化目标与评分 (不变):

- **最终评分** = **Execution Time = Estimated Clock Period(ns) × Cosim Latency(cycles)**
- **时序约束**: 若 **Slack ≤ 0 扣 10 分**。其中 Slack = Target × 0.9 − Estimated。
- **资源约束**: 资源使用率（LUT, FF, BRAM, DSP）超出 100% = 该题 0 分。

新的核心战略与指导思想:

1. **战略重心转移**: 我们之前的策略（在固定 Latency 下压榨 Estimated）已遇到瓶颈。现在的**首要任务**是：**在 `Estimated` 时钟周期不显著恶化的前提下，以最低的 `Latency` (执行周期数) 为核心优化目标。**
2. **激进的“资源换性能”**: 为了达成最低 `Latency`，我们采取**不计成本的资源换性能策略**。你可以大胆提出使用更多并行计算、深度流水线、数据复制、乒乓操作等任何消耗资源但能降低周期的方案。
3. **鼓励算法级重构**: 我们鼓励对 **`top` 函数内部调用的子函数进行大规模的算法级重构**。这意味着可以彻底改变原有函数的实现逻辑、数据流路径和计算方式，只要最终的功能等价即可。
4. **遵循官方最佳实践**: 所有的优化建议和代码实现，都应优先参考 **Xilinx/AMD 官方文档，特别是 UG1399 (Vitis HLS 用户指南)** 中关于延迟优化 (Latency Optimization)、数据流 (Dataflow)、循环依赖性 (Loop Dependencies) 等章节的官方推荐做法。

严格的开发限制 (最重要，保持不变):

- **工具与环境**: Xilinx Vitis HLS 2024.2, WSL 环境。
- **代码修改范围**: **只能**修改 Vitis Libraries 中 `L1/include/` 目录下的核心算法头文件（`.hpp`）。
- **测试平台不变**: **绝对不能**修改 `L1/tests/` 或 `L2/tests/` 目录下的任何测试文件。
- ✅ **允许**: 修改 `.hpp` 里的任何内部结构：重构子函数、使用 `#pragma HLS DATAFLOW`、`PIPELINE`、`UNROLL`、`ARRAY_PARTITION`、`BIND_STORAGE` 等。
- ✅ **允许**: 为了数据流或并行化，在函数内部复制算子/寄存器、增加缓存/FIFO。
- ✅ **允许**: 修改 Tcl/Makefile 中的 `create_clock -period` 以探索时序边界，但不允许tcl的其他内容
- ❌ **禁止**: 修改 `top` 函数的**端口**（名称、数量、类型、位宽、顺序）。
- ❌ **禁止**: 修改最终的输出结果，必须与原始算法在功能上完全等价。

### **模型输出摘要**

模型接收了新的优化战略，并提出了一系列以降执行周期（Latency）为核心的、可落地的微架构优化方案。主要建议包括：

- **方案 A (架构重构)**：将算法从“按行”彻底重构为“按列并行推进”。
- **方案 B (备选架构)**：采用更复杂的块分解算法，将计算核心转移到高度优化的 GEMM（矩阵乘法）上。
- **方案 C (算术单元优化)**：融合对角线计算中的 `sqrt` 和 `rsqrt`，用一次低延迟的 `rsqrt` + 乘法替代高延迟的 `sqrt` IP 核。模型标记此方案为“易落地”。
- **方案 D (内循环优化,)**：在方案 A 的基础上，对 PE 内部的点积计算（k 循环）进行**向量化**，进一步提升并行度。
- **方案 E/F (微调)**：包括索引计算线性化、延迟零写回、HLS 指令精细化绑定等，用于在后期稳定性能和清理“气泡”。

### **人工审核与采纳情况**

我们决定首先实施**方案 A**，以求快速验证最大幅度的性能提升。

---

## **使用场景 3：关键代码实现（方案A）**

在确定了核心优化方案后，我们要求模型提供可直接编译和测试的代码，以快速落地“按列并行推进“。

### **Prompt设计：**

我们决定采纳方案A。请提供一版更改后可编译的代码。要求：

1. 重构核心循环结构
2. 解决访存冲突
3. 设计广播机制
4. 在函数顶部添加版本号和简要功能注释。
5. 请简要分析此更改是否会影响最终的压缩比。

### **模型输出摘要**

模型根据指令生成了应用方案A后的代码补丁。同时模型在分析部分指出，该策略会使 BRAM 资源消耗量与并行度 `P_PAR` 成正比，是一种典型的“以面积换性能”设计，是确保 `II=1` 稳定流水线的必要代价。

### **人工审核与采纳情况**

在进行 HLS 综合审查后，我发现了一个隐藏的性能缺陷：所有并行单元在启动时都会争抢访问顶层的单端口输入数组 `A`，导致并行设计因访存冲突而失效，启动间隔（II）远大于 1。为此，我指导模型进行了关键修正，即在并行计算前增加一个数据预取阶段，将所需数据从 `A` 提前加载到一个完全分区的本地寄存器缓存 `anchor` 中。这一干预彻底解决了输入瓶颈，使并行循环成功达到 `II=1` 。

---

## **使用场景 4：实现 K 维向量化 (方案 D)**

### **Prompt设计：**

当前 Latency 为 3735 周期。请在当前 vA-1.1 版本的基础上，继续实施方案 D，即对 PE 内部的点积计算（k 循环）进行向量化，以进一步降低延迟。

### **模型输出摘要**

模型生成了 vA-2.0 版本，在上一版基础上增加了 k 维向量化：

1. 引入 `UF` (Unroll Factor) 参数，将内层点积循环改造为“外层以步长 `UF` 流水，内层 `UNROLL`”的结构，实现了单拍内处理 `UF` 个元素的向量化计算。
2. 模型正确地推断出，`UF` 的引入会使每个 PE 在一拍内需要 `UF` 个读端口。因此，它自动将存储副本数量从 `P_PAR` 扩展到了 `R_REP = P_PAR * UF` 份，并为每个 unroll 的 lane 分配了专属的存储副本索引 `rep_idx = p * UF + u`，解决了访存冲突。

### **人工审核与采纳情况**

采纳补丁，Cosim一次性PASS。

---

## **使用场景 5：优化核心算术单元 (rsqrt)**

### **Prompt设计：**

HLS 报告显示，`x_sqrt` 模块仍是延迟瓶颈。请为 `cholesky_rsqrt` 子函数提供一版优化的代码，移除 `x_sqrt` 和除法操作。用数学公式（latex）对比说明原理。

### **模型输出摘要**

模型提供了一版高度优化的 `cholesky_rsqrt` v2.1。其核心思想是：

1. 对于定点数特化版本，先将输入转换为 `float`，调用一个低延迟的 `x_rsqrt` IP 快速得到一个近似解。
2. 将结果转回定点域，再通过**一次牛顿-拉夫逊迭代** (`y = y * (1.5 - 0.5*x*y*y)`) 来提升精度。
3. 整个过程被完全流水化（`II=1`），且仅包含乘法和加/减法，硬件实现效率极高。

### **人工审核与采纳情况**

代码被直接采纳后，HLS 报告中的 `x_sqrt` 模块消失，Latency 大幅降低至 1903 周期，取得了决定性的优化成果。

---

## **使用场景 6：针对小矩阵的微架构优化**

### **Prompt设计：**

当前 Latency 为 1903 周期。我的测试平台主要使用 3x3 的小矩阵。请问针对这种小尺寸矩阵，是否还有进一步的优化空间？请优先提供最高优先级的方案及其代码实现。

### **模型输出摘要**

模型指出，对于 `RowsColsA ≤ 8` 的小矩阵，BRAM 的访问延迟和多副本的同步开销占比更高，不再是最优选择。它给出了 P1 级优先方案：

- **小矩阵“寄存器 Bank”专用路径**：当矩阵尺寸小于等于 8 时，不再使用 BRAM `L_rep` 副本，而是改用一个 `L_bank[RowsColsA][RowsColsA]` 的二维数组，并对其两个维度都应用 **`#pragma HLS ARRAY_PARTITION complete`**。
- **原理**：这将 `L_bank` 彻底分解为独立的寄存器，实现了任意元素的零延迟、无冲突并行访问，从而消除了 BRAM 延迟和副本同步开销。
- 模型提供了一个 `if (RowsColsA <= 8)` 的分支结构，在 `choleskyAlt` 内部实现了小矩阵和大矩阵两条硬件路径的自动选择。

### **人工审核与采纳情况**

该建议精准地抓住了小矩阵场景下的性能瓶颈。代码被采纳后，**Latency 从 1903 周期降至 1831 周期**，进一步逼近了理论下限。

---

## **总结**

### **整体贡献度评估**

- **大模型在本项目中的总体贡献占比**：约 **40%**
- **主要帮助领域**：架构方案探索、HLS pragma专业指导、性能瓶颈分析、可编译代码生成。
- **人工介入与修正比例**：约 **60%**。我的核心贡献在于：
    1. **制定与调整顶层战略**：在关键节点决策优化重心的转移。
    2. **方案筛选与决策**：从模型提供的多种可能性中，结合风险、收益和项目阶段，选择最合适的实施路径。
    3. **批判性审核与实证**：对模型的建议进行独立的仿真和综合验证，并基于实测数据进行最终决策。
    4. **闭环反馈与指导**：在AI方案不达预期时，提供数据驱动的反馈，主导其进行方案修正。

### **学习收获**

通过与大模型进行深度、专业的交互，我不仅高效地完成了复杂的HLS性能优化，更在实践中巩固了从顶层架构设计到微观代码调优的全链路能力。这次经历证明，将个人开发中的工程经验与大模型的广博知识和快速生成能力相结合，是未来高性能硬件设计与创新的高效范式。