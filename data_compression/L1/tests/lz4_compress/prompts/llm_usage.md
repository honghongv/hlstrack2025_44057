# 大模型辅助使用记录

## 基本信息

- **模型名称**：OpenAI codex，juice 200
- **提供方 / 访问方式**：OpenAI API ([api.openai.com](http://api.openai.com/))
- **使用日期**：2025-10-26
- **项目名称**：LZ4_Compress L1 算子优化

---

## **使用场景 1：性能瓶颈分析**

在开始优化前，我们首先在AI指导下完成了性能瓶颈的分析。这一阶段的主要目标是确保优化方向正确，并为后续优化提供参考基准和对比材料。

### **Prompt设计：**

我正在优化 Vitis 库中的 data_compression::lz4_compress算子。

这是官方 LZ4算子的核心代码：

- `// --- 贴上官方原始核心代码 ---*`

这是它未经优化的 HLS 综合报告摘要：

`// --- 基准 HLS 报告中的 P&R---`

**【目标】**

我的优化目标是实现理论上的最高吞吐率，即降低端到端延迟，保持主循环流水线启动间隔（II）为 1。资源消耗是次要考虑因素。

**【诊断问题】**

1. 请解读这份报告。基于代码和报告，**根本原因**是什么导致了性能不佳（ Latency 过高）？
2. 代码中是否存在特定的**数据依赖**（如循环携带依赖）或**存储瓶颈**（如单端口 BRAM 访问冲突）？请指出具体是哪几行代码导致了这些问题。

### **模型输出摘要**

模型准确地解读了HLS报告，并一针见血地指出，基准设计的性能瓶颈主要源于三个方面：

1. **哈希字典的结构性访问冲突**：在核心的`lz_compress`循环中，每个时钟周期都需要对哈希字典进行一次读（查找旧匹配）和一次写（更新为当前条目）。这种对同一存储资源的并发读写访问（RAW/WAW hazard）是导致流水线启动间隔（II）被强制推高至2的根本原因。
2. **串行的匹配长度计算逻辑**：用于计算`match_length`的内部循环采用了逐字节比较并依赖一个`done`标志位提前退出。这种设计形成了**循环携带依赖（Loop-carried Dependency）**，不仅拉长了单拍内的组合逻辑关键路径，也进一步固化了II=2的性能瓶頸。
3. **无法重叠的尾部处理**：设计中存在多个独立的尾部数据处理循环（如`lz_compress_leftover`, `lz_left_bytes`）。这些循环在主数据流处理完毕后才串行执行，形成了固定的延迟“尾巴”，无法与核心计算过程并行，影响了整体的端到端性能。

### **人工审核与采纳情况**

模型提供的瓶颈分析系统且专业，帮助我构建了初步的优化思路。

---

## **使用场景 2：优化策略制定**

在了解算子优化瓶颈后，我在llm指导下完成了HLS 性能优化策略制定和代码重构方案探索。

### **Prompt设计：**

你好，我们将继续进行一个高层次综合（HLS）优化任务。请你继续扮演一名资深的 FPGA HLS 专家。

核心优化目标与评分 (不变):

- **最终评分** = **Execution Time = Estimated Clock Period(ns) × Cosim Latency(cycles)**
- **时序约束**: 若 **Slack ≤ 0 扣 10 分**。其中 Slack = Target × 0.9 − Estimated。
- **资源约束**: 资源使用率（LUT, FF, BRAM, DSP）超出 100% = 该题 0 分。

新的核心战略与指导思想:

1. **战略重心转移**: 我们之前的策略（在固定 Latency 下压榨 Estimated）已遇到瓶颈。现在的**首要任务**是：**在 `Estimated` 时钟周期不显著恶化的前提下，以最低的 `Latency` (执行周期数) 为核心优化目标。**
2. **激进的“资源换性能”**: 为了达成最低 `Latency`，我们采取**不计成本的资源换性能策略**。你可以大胆提出使用更多并行计算、深度流水线、数据复制、乒乓操作等任何消耗资源但能降低周期的方案。
3. **鼓励算法级重构**: 我们鼓励对 **`top` 函数内部调用的子函数进行大规模的算法级重构**。这意味着可以彻底改变原有函数的实现逻辑、数据流路径和计算方式，只要最终的功能等价即可。
4. **遵循官方最佳实践**: 所有的优化建议和代码实现，都应优先参考 **Xilinx/AMD 官方文档，特别是 UG1399 (Vitis HLS 用户指南)** 中关于延迟优化 (Latency Optimization)、数据流 (Dataflow)、循环依赖性 (Loop Dependencies) 等章节的官方推荐做法。

严格的开发限制 (最重要，保持不变):

- **工具与环境**: Xilinx Vitis HLS 2024.2, WSL 环境。
- **代码修改范围**: **只能**修改 Vitis Libraries 中 `L1/include/` 目录下的核心算法头文件（`.hpp`）。
- **测试平台不变**: **绝对不能**修改 `L1/tests/` 或 `L2/tests/` 目录下的任何测试文件。
- ✅ **允许**: 修改 `.hpp` 里的任何内部结构：重构子函数、使用 `#pragma HLS DATAFLOW`、`PIPELINE`、`UNROLL`、`ARRAY_PARTITION`、`BIND_STORAGE` 等。
- ✅ **允许**: 为了数据流或并行化，在函数内部复制算子/寄存器、增加缓存/FIFO。
- ✅ **允许**: 修改 Tcl/Makefile 中的 `create_clock -period` 以探索时序边界，但不允许tcl的其他内容
- ❌ **禁止**: 修改 `top` 函数的**端口**（名称、数量、类型、位宽、顺序）。
- ❌ **禁止**: 修改最终的输出结果，必须与原始算法在功能上完全等价。

### **模型输出摘要**

模型接收了新的优化战略，并提出了一系列以降执行周期（Latency）为核心的、可落地的微架构优化方案。主要建议包括：

- **方案A（Epoch标记失效化）**：通过增加一个`tag` BRAM和一个`curEpoch`全局计数器，实现O(1)复杂度的逻辑字典清空，从而彻底移除耗时约2048周期的`dict_flush`物理初始化循环。这是模型首推的、预期收益最高的方案。
- **方案 B（备选同幅度）：**Ping-Pong 双字典 Bank
- **方案C（循环融合）**：将填充滑动窗口的独立预热循环，以及多个分离的尾部数据处理循环，各自合并到主处理流程中，以消除独立流水线区域的启动/排空开销。
- **方案D（并行化重构）**：将计算匹配长度的、带有`done`标志位的串行循环，重构为“并行位比较+优先编码器”的组合逻辑电路，旨在缩短关键路径，为提升时钟频率（Fmax）预留空间。
- **方案 E（微调 + 抗抖）：**存储绑定与端口使用的刚性约束

### **人工审核与采纳情况**

我完全认同其将方案A（Epoch失效化）列为最高优先级的判断，因为它直接解决了最大的Latency瓶颈（`dict_flush`循环），且风险可控。因此，我们决定将方案A作为第一阶段的核心优化任务进行实施，并暂缓考虑其他方案，以求快速验证最大幅度的性能提升。

---

## **使用场景 3：关键架构重构与代码实现**

在确定了核心优化方案后，我们要求模型提供可直接编译和测试的代码，以快速落地“Epoch失效化”架构。

### **Prompt设计：**

我们决定采纳方案A（Epoch标记失效化）。请提供一版更改后可编译的代码。要求：

1. 移除`dict_flush`循环。
2. 引入`tag`数组和`curEpoch`计数器，并重构字典的读写逻辑以实现按需失效。
3. 在函数顶部添加版本号和简要功能注释。
4. 请简要分析此更改是否会影响最终的压缩比。

### **模型输出摘要**

模型根据指令生成了应用方案A后的代码补丁。模型同时确认，该修改仅改变了字典的初始化方式，并未触及任何匹配算法的核心逻辑，因此压缩比与原始实现完全等价。

### **人工审核与采纳情况**

我们直接将模型生成的代码替换到项目中。模型生成的代码在结构上基本正确，但在HLS指令的运用上存在疏漏。初版代码忘记为新增的`tag`数组添加`#pragma HLS dependence variable=tag inter false`指令。这导致HLS工具保守地认为`tag`的读写存在跨迭代依赖，从而将主循环的II（启动间隔）劣化为2。通过代码审查，我定位到这一问题，并手动添加了该指令。

---

## **使用场景 4：增量优化与微架构迭代**

在完成核心架构重构后，我们进入了精细的“抠周期”阶段。我们利用模型进行了一系列小步快跑式的微架构优化。

### **Prompt设计：**

（分多轮进行）

1. “Latency已优化到1346。请在此基础上尝试方案C，将预热窗口（`present_window`的初始化）合并入主循环，以消除独立的预热循环开销。”
2. “方案C使Latency降至1345。请继续分析，是否有能够小幅砍掉cycles的方案，例如对尾部处理逻辑的优化。”
3. “我们已采纳尾部融合方案，Latency降至1343。请对`lzBestMatchFilter`和`lzBooster`模块进行类似的尾部融合优化。”

### **模型输出摘要**

模型在每一轮都准确理解了我们的增量优化意图，并提供了精确的代码补丁：

- **预热融合**：通过引入`valid`计数器，将窗口预热的逻辑无缝并入`lz_compress`主循环的起始阶段。
- **尾部融合**：将原先分离的`lz_compress_leftover`和`lz_left_bytes`两个循环，合并为一个单一的、逻辑分阶段的`tail_fused`循环。
- **其他模块融合**：为`lzBestMatchFilter`和`lzBooster`提供了类似的尾部处理融合代码。

### **人工审核与采纳情况**

我们逐一采纳了模型提出的循环融合方案。在审查其生成的`tail_fused`（尾部融合）循环时，发现了llm生成的尾部循环在处理边界条件时，错误地将`present_window`的最后一个字节输出了两次，同时遗漏了从输入流中读取的第一个`LEFT_BYTES`字节。我随即重写了`tail_fused`循环的内部逻辑，通过 `if (t < (MATCH_LEN - 1))` 条件判断，精确地划分了“从窗口输出”和“从输入流输出”两个阶段，确保了数据流的正确衔接。

---

## **使用场景 5：优化策略转型：从Latency到Timing**

当Latency优化进入瓶颈区后，我们将优化目标转向降低**Estimated Clock Period**，以进一步提升最终得分。

### **Prompt设计：**

我们的Latency大约已经到了下限。现在，请提出能在不改变II和Latency的前提下，再压低`Estimated Clock Period`的方案。资源（BRAM, LUT, FF）余量充足。

### **模型输出摘要**

模型提出了包括“并行前缀匹配”、“窄位宽算术”在内的多项Timing优化策略。在实现“并行前缀匹配”时，它提供了一版代码，通过`run[m] = run[m] & run[m-1]`来构造一个前缀“全1”向量，再对该向量进行求和。

### **人工审核与采纳情况**

模型提出的策略非常专业，精准地定位了影响Fmax的几个典型HLS设计模式。我们要求模型提供最终集成了所有Timing优化方案的可编译代码。

---

## **总结**

### **整体贡献度评估**

- **大模型在本项目中的总体贡献占比**：约 **40%**
- **主要帮助领域**：架构方案探索、HLS pragma专业指导、性能瓶颈分析、可编译代码生成。
- **人工介入与修正比例**：约 **60%**。我的核心贡献在于：
    1. **制定与调整顶层战略**：在关键节点决策优化重心的转移。
    2. **方案筛选与决策**：从模型提供的多种可能性中，结合风险、收益和项目阶段，选择最合适的实施路径。
    3. **批判性审核与实证**：对模型的建议进行独立的仿真和综合验证，并基于实测数据进行最终决策。
    4. **闭环反馈与指导**：在AI方案不达预期时，提供数据驱动的反馈，主导其进行方案修正。

### **学习收获**

通过与大模型进行深度、专业的交互，我不仅高效地完成了复杂的HLS性能优化，更在实践中巩固了从顶层架构设计到微观代码调优的全链路能力。这次经历证明，将个人开发中的工程经验与大模型的广博知识和快速生成能力相结合，是未来高性能硬件设计与创新的高效范式。