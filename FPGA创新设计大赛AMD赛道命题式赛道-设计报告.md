# FPGA创新设计大赛AMD赛道命题式赛道 - 设计报告

# 1.项目概述

## 1.1 项目背景

本项目是 FPGA创新设计大赛 AMD赛道命题式赛道 的参赛作品。竞赛要求参赛者基于 Vitis HLS 工具，对 Vitis Libraries 中提供的三个 L1 级别算法（SHA-256、LZ4 Compress 和 Cholesky）进行深度优化。竞赛的核心目标是在保证算法功能完全正确的前提下，通过高层次综合（HLS）的各种优化技术，最大限度地缩短算法在目标FPGA平台上执行所需的总时间（Execution Time）。

## 1.2 设计目标

本项目旨在通过一系列 HLS 优化策略，达成以下具体目标：

- **功能目标：** 完整实现 SHA-256、LZ4 Compress 和 Cholesky 三个算法的硬件加速。优化后的设计必须通过 C-Simulation 和 Co-simulation 验证，确保其输出结果与官方原始实现完全一致，保证功能的正确性。
- **性能目标：** 核心性能目标是**最小化算法的执行时间（Execution Time）**。该时间由综合后预估的时钟周期（Estimated Clock Period）与联合仿真测得的延迟（Co-simulation Latency）的乘积决定。在追求极致性能的同时，力求保证时序收敛（Slack > 0），以避免因时序违例而导致的评分惩罚。
- **资源优化目标：** 确保优化后的设计所使用的逻辑资源（LUT、FF）、片上存储（BRAM）和数字信号处理单元（DSP）的总量不超过目标平台（xc7z020）的容量限制。所有设计必须是可综合、可布局布线的。

## 1.3 技术规格

- **目标平台：** AMD PYNQ-Z2
- **开发工具：** Vitis HLS 2024.2
- **编程语言：** C++
- **验证环境：**本项目在 **Linux**环境下进行开发与验证。完整的验证流程遵循标准的 Vitis HLS 设计方法，具体包括csim，csynth，cosim和impl。

---

# 2. **SHA-256 算子优化设计**

## 2.1 **设计原理和功能**

### 2.1.1 算法原理

**SHA-256** 对任意长度消息进行填充、分块（512bit/块），并以 64 轮压缩函数迭代更新 8 个 32 位工作寄存器 $(a,b,c,d,e,f,g,h)$，最终与初始向量相加得到摘要。

- **消息调度（Schedule）**
    
    对每个 512bit 块，先按大端得到 $M0∼M15$，再生成 64 个调度字：
    
    $W_t=\begin{cases}M_t,& 0\le t<16\\σ _1!\left(W_{t-2}\right)+W_{t-7}+\sigma_0!\left(W_{t-15}\right)+W_{t-16},& 16\le t<64\end{cases}$
    
    其中，
    
    $\sigma_0(x)=\mathrm{ROTR}^7(x)\oplus \mathrm{ROTR}^{18}(x)\oplus (x\gg3)$
    
    $\sigma_1(x)=\mathrm{ROTR}^{17}(x)\oplus \mathrm{ROTR}^{19}(x)\oplus (x\gg10)$
    
- **轮函数**
    
    每一轮用常量 $Kt$ 与本轮 $Wt$ 更新工作寄存器：
    
    $T_1 = h + \Sigma_1(e) + \mathrm{Ch}(e,f,g) + K_t + W_t$
    
    $T_2 = \Sigma_0(a) + \mathrm{Maj}(a,b,c)$
    
    $\Sigma_0(x)=\mathrm{ROTR}^{2}(x)\oplus\mathrm{ROTR}^{13}(x)\oplus\mathrm{ROTR}^{22}(x)$
    
    $\Sigma_1(x)=\mathrm{ROTR}^{6}(x)\oplus\mathrm{ROTR}^{11}(x)\oplus\mathrm{ROTR}^{25}(x)$
    
    $\mathrm{Ch}(x,y,z)=(x\wedge y)\oplus(\neg x\wedge z) , \mathrm{Maj}(x,y,z)=(x\wedge y)\oplus(x\wedge z)\oplus(y\wedge z)$
    
    $(a,b,c,d,e,f,g,h)\leftarrow(T_1+T_2, a,b,c,d+T_1,e,f,g)$
    
- **块/消息级收尾**
    
    64 轮后把 $(a..h)$ 分别与上一块的 $(H0..H7)$ 相加；全部块处理完毕后，拼接得到 256/224bit 摘要。
    

### 2.1.2 系统架构设计 (优化后)

为最大化硬件并行度，本设计采用DATAFLOW架构，将算法映射为独立的流式处理单元，并通过复制LANE来线性扩展系统吞吐能力。

- **顶层架构：**
    - **Stage 0：预处理（preProcessing）**
        
        从消息与长度流生成 512bit 块流、每消息块数与结束标志。
        
    - **Stage 1：分发（dispatcher）**
        
        采用“整消息轮询”，同一消息的所有块固定到同一 LANE，并输出顺序通道，末端据此按输入顺序合并结果。
        
    - **Stage 2：每LANE的消息调度与压缩**
        
        串联“W 生成（带块/消息旁带）→ 压缩核（直接消费旁带）”。
        
    - **Stage 3：收集（collector）**
        
        根据 Stage1 的顺序通道，从指定 LANE 取摘要并按输入顺序输出；不影响各 LANE 内部状态机。
        
- **核心计算模块设计：**
    1. **模块A（generateMsgSchedule）：消息调度**
        
        本模块把每个 512bit 块转成 64 个 $Wt$ 值，并在输出 $Wt$ 的同时附带“该块是否为当前消息最后一块”和“消息是否结束”的两个标志，供后级压缩核直接使用。原版只输$Wt$，块/消息边界需要上层用块数流来判断。优化版还采用 16 槽环形缓冲生成 $t≥16$  的 $Wt$  保持 $II=1$ 连续出数。
        
        - **要点：**
            - 输入/输出：输入是块流，输出是 $*Wt*$ 流；旁带输出 `w_blk_last_strm`（块末）和 `msg_eos_strm`（消息结束）。
            - 生成方式：$t<16$ 直接取块；$t>=16$ 用环形 16 槽 + 小 σ 组合得到新 $*Wt*$。原版用“移位数组”写法。
            - 资源和时序：W 与块数组完全分割；小 σ 的求和绑定 DSP，缩短加法链。
    2. **模块B（sha256_iter+sha256Digest_onW）：压缩循环核（64 轮）**
        
        读取 W 流并完成 64 轮压缩；通过模块A的旁带信号直接识别块末和消息结束，在消息边界输出摘要。相较原版的 `sha256Digest`，这里不再接收 `dup_strm` 复制出来的块数/结束流。
        
        - **要点：**
            - 轮常量表 $K[64]$ 完全分割，保证每拍并行读；最终把工作寄存器与历史状态相加后输出。
            - 单轮实现：`Ch(e,f,g)` 改写为 `g ^ (e & (f ^ g))`；`Maj(a,b,c)` 改写为 `(a & b) ^ (c & (a ^ b))` 。
    3. **模块C（sha256_dispatch / sha256_collect）：分发与收集**
        
        分发按“整消息轮询”把同一消息的所有块固定到同一 LANE；收集依据顺序通道按输入顺序输出摘要。原版是单通道流程，没有这两个多 LANE 组件。
        
        - **要点**
            - 分发：输出每条消息的块数与块数据到选中的 LANE，并写入顺序通道。
            - 收集：按顺序通道指定的 LANE 读取摘要并输出，只消费对应的标志位；最后统一结束。

## 2.2 **优化方向选择与原理**

### 2.2.1 优化目标分析

根据对赛题初始代码的综合结果P&R的分析，我们了解到当前 64 轮内环已做到 II=1，性能瓶颈主要是每拍组合路径过长（T1/T2 链路：旋转/异或 + 多操作数加法），其次是消息调度 W[t] 计算的四操作数长链。据此，我们把本设计的优化目标定为：

- 降低端到端延迟
- 提升并行与可扩展性
- 稳定单轮 II=1 的同时拉高 Fmax

### 2.2.2 具体优化策略与 HLS 指令应用

针对上述瓶颈，我进行了深入的架构性重构。优化的核心思想是：**在算法功能等价的前提下，通过重构数据流动与计算方式，使其更符合 FPGA 硬件的并行与流水线特性。**

1. **存储优化**
    - **数据重用策略：从移位寄存器到循环缓冲**
        - **问题**：原始 `generateMsgSchedule` 中更新 W 数组的移位操作（`W[j] = W[j+1]`）硬件实现效率很低。
        - **原理与实现**：对 `generateMsgSchedule` 模块进行了关键重构。通过对比代码可以发现，优化后的设计将 `W[16]` 数组从一个移位寄存器重构为一个循环缓冲。
            - **原始代码**：
                
                `for (unsigned char j = 0; j < 15; ++j) { W[j] = W[j + 1]; }
                W[15] = Wt;`
                
            - **优化代码**：
                
                `W[t & 15] = Wt; *// 使用模运算实现循环写入*`
                

---

1. **流水线优化**
    - **流水线插入与数据依赖处理：重构单轮哈希计算**
        - **问题**：原始 `sha256_iter` 内的 `T1` 和 `T2` 计算存在过长的组合逻辑链。
        - **原理与实现**：通过对比新旧 `sha256_iter` 函数，我们用逻辑等价但硬件实现更浅的表达式替换了原有的 `CH` 和 `MAJ` 函数。例如，`MAJ(a,b,c)` 从三输入与或逻辑，重构为 `(a & b) ^ (c & (a ^ b))`。
    - **循环展开与流水线设计**
        - **问题**：原始 `preProcessing` 模块中，处理消息尾部的循环 `LOOP_SHA256_GEN_COPY_TAIL_PAD_ONE`存在两次循环迭代之间的流水线重启延迟 。
        - **原理与实现**：在优化后的代码中，对 `preProcessing` 模块中的 `LOOP_SHA256_GEN_FULL_BLKS` 和 `LOOP_SHA256_GEN_COPY_TAIL_PAD_ONE` 添加了 `#pragma HLS PIPELINE rewind`，消除了循环迭代间的气泡。

---

1. **并行化优化**
    - **任务级并行：引入多LANE处理架构**
        - **问题**：原始设计为单流水线结构，无法同时处理多个消息，吞吐率受限于单个 SHA-256 引擎的计算能力。
        - **原理与实现**：这是本次优化中优化幅度最大的架构改动。我引入了任务级并行机制。
            1. **新增 `sha256_dispatch` 和 `sha256_collect` 模块**：`dispatch` 模块负责将输入的不同消息以轮询方式分发到 LANES 个并行的处理通道中（考虑到资源限制，本算子中`#define SHA256_LANES 2`  ）。`collect` 模块则根据 `dispatch` 记录的顺序，从各 `Lane` 中收集计算结果，确保输出顺序的正确性。
            2. **顶层 `UNROLL` 实例化**：在顶层 `sha256_top` 中，通过 `for` 循环和 `#pragma HLS UNROLL`，物理上复制并实例化了 `LANES` 份完整的 `generateMsgSchedule` 和 `sha256Digest_onW` 模块。
    - **数据级并行：基于边带流的模块解耦**
        - **问题**：原始 `dup_strm` 模块耦合了控制流，阻碍了 `DATAFLOW` 区域内各模块的最大化并行。
        - **原理与实现**：我彻底移除了 `dup_strm` 模块，并重构了 `generateMsgSchedule` 与 `sha256Digest_onW` 之间的接口。
            - **原始接口**：`dup_strm` 单独发送控制信号 `nblk_strm`。
            - **优化后接口**：`generateMsgSchedule` 在生成 `w_strm` 数据流的同时，并行地输出了两条边带：`w_blk_last_strm`（块结束标志）和 `msg_eos_strm`（消息结束标志）。
    
    ---
    
2. **关键 HLS 指令优化**
    
    `#pragma HLS PIPELINE II=1 rewind`
    
    > 目的：服务于流水线优化。通过 rewind 选项消除流水线循环间的气泡。
    > 
    
    `#pragma HLS RESOURCE variable=... core=FIFO_SRL`
    
    > 目的：服务于并行化优化。指定使用 SRL实现，缓解背压。
    > 
    
    `#pragma HLS UNROLL` (应用于 `LANES` 循环)
    
    > 目的：服务于任务级并行。物理复制计算核心，是实现多 Lane 并行处理架构的根本指令。
    > 
    
    `#pragma HLS RESOURCE variable=... core=FIFO_BRAM`
    
    > 目的：服务于存储优化。对于位宽较宽的 FIFO（如 `blk_strm`），显式指定使用 BRAM 实现。
    > 

## 2.3 **LLM 辅助优化记录**

详见llm_usage，本报告中选取2个关键的交互记录。

---

### 使用场景 3**：关键函数实现**

**Prompt设计：**

请提供方案B+E的C++实现。要求：

1.请重构`generateMsgSchedule`和`sha256Digest`的函数签名，移除`nblk_strm`和`end_nblk_strm`。

2.请更新`sha256_top`顶层函数，移除对`dup_strm`模块的调用，并正确连接新的边带信号。

3.请在`sha256_top`中，为关键的`hls::stream`数组（`w_lane`和`hash_lane`）提供使用`FIFO_SRL`实现深度缓冲的pragma指令。

4.在每个修改后的函数顶部，添加版本号和简要功能注释。

**模型输出摘要**

模型根据指令生成了应用方案B和方案E后的代码补丁。

**人工审核与采纳情况**

模型生成的代码在结构和接口上基本正确，但在`sha256Digest_onW`函数的循环控制逻辑中引入了死锁风险。初版代码在`sha256Digest_onW`的`do-while`循环中，将`blk_last = w_blk_last_strm.read()`操作放在了64轮迭代**之后**。在Csim中，这并未立即暴露问题。但在进行Cosim时，我发现当处理多块消息时，系统会在处理完第一块后挂起。我进行了代码修正，修正后Cosim顺利PASS。

---

### 使用场景 4**：再次分析P&R并定位气泡**

在获得初步优化结果后，我对报告进行了审查，并发现：核心循环的实际周期（66）与理论周期（64）存在2个周期的微小差异。

**Prompt设计：**

我已应用了上一轮的优化。分析报告发现一个性能疑点：

- **瓶颈描述**：`generateMsgSchedule`和`sha256Digest`内部的64次核心循环，其报告Latency均为66个周期，而非理论上的64周期。
- **问题**：请解释这额外的2个周期来源于何处，并提出最直接的HLS pragma解决方案来消除这种开销。

**模型输出摘要**

模型指出，当一个循环被连续调用时，标准流水线会在每次调用间产生空闲周期。llm建议，对这两个循环应用`#pragma HLS pipeline II=1 rewind`指令，以实现“回卷流水线”，消除该开销。

**人工审核与采纳情况**

采纳rewind建议，气泡顺利消除。

---

## **2.4 优化前后性能与资源对比报告**

### 2.4.1 综合结果对比 (资源与性能表格)

- **资源使用对比（来自export_impl.rpt）**
    
    
    | **资源类型** | **优化前** | **优化后** | **改善幅度** | **利用率(优化前)** | **利用率(优化后)** |
    | --- | --- | --- | --- | --- | --- |
    | BRAM | 1 | 91 | +9000.00% | 0.36% | 32.50% |
    | DSP | 0 | 0 | N/A | 0.00% | 0.00% |
    | LUT | 7774 | 17894 | +130.18% | 14.61% | 33.64% |
    | FF | 13792 | 16380 | +18.76% | 12.96% | 15.39% |
- **性能指标对比**
    
    
    | **性能指标** | **优化前** | **优化后** | **改善幅度** |
    | --- | --- | --- | --- |
    | 延迟(Latency) | 809 | 462 | -42.90% |
    | EstimatedClockPeriod(ns) | 12.882 | 12.550 | -2.58% |

### 2.4.2 详细分析 (解释数据变化原因)

- **资源优化分析**
    
    **BRAM优化效果：**
    
    BRAM使用量剧增，这是实现多Lane并行架构和优化存储映射策略的直接结果。
    
    **逻辑资源优化效果：**
    
    LUT和FF的增长主要源于通过`UNROLL`指令物理复制计算核心，是实现任务级并行所付出的预期面积成本。
    
- **性能优化分析**
    
    **流水线效率提升：**
    
    流水线效率的提升并非来自II，而是通过微架构重构提升了Fmax，并通过解耦数据流、消除同步点显著减少了流水线停顿。
    
    **延迟优化效果：**
    
    延迟降低42.9%得益于：移除了`dup_strm`同步瓶颈、使用`rewind`消除了循环间隙、以及通过深度FIFO平滑了数据流。
    

### 2.4.3 正确性验证

- **仿真配置：**
    
    采用赛题官方给出的测试用例
    
- **仿真结果：**
    
    功能正确性：✅ 通过 
    
- **仿真结果：**
    - 时序正确性：✅ 通过
    - 接口兼容性：✅ 通过
    - 性能匹配度：[100%]

## **2.5 本算子遇到的问题与解决方案**

### **2.5.1 遇到的主要问题**

1. 总周期偏大
2. 关键路径偏深（Estimated 高）
3. 偶发背压导致隐形气泡

### **2.5.2 采用的解决方案**

1. 去 `dup_strm`，边带信号并入 W 
2. 关键 FIFO 加深并用 SRL
3. 关键循环加 `#pragma HLS PIPELINE II=1 rewind`
4. 采用更浅布尔/异或表达式

---

# 3. LZ4 **算子优化设计**

## 3.1 **设计原理和功能**

### 3.1.1 算法原理

**LZ4** 是一种基于字典压缩思想的、面向字节流的高速无损压缩算法。其核心原理是在一个滑动窗口内，为当前待压缩的数据序列寻找并替换掉在此前已出现过的、最长的重复序列。

- **核心思想**
    
    通过哈希表（在硬件实现中通常为字典RAM）快速定位潜在的匹配项。对当前输入字节序列计算哈希值，以该哈希值作为地址访问字典，获取历史中具有相同哈希值的序列位置。
    
- **数据编码**
    
    LZ4 的输出由两种基本单元构成：**字面量和匹配**。
    
    - **字面量**：未找到有效匹配的原始、未经压缩的字节序列。
    - **匹配**：当找到一个长度不小于最小匹配长度（`MIN_MATCH`）的重复序列时，用一个紧凑的 **<长度, 偏移量>** 对来表示。
- **压缩流程**
    
    算法逐字节地处理输入流，维护一个滑动窗口。对于窗口内的当前序列，计算哈希并查询字典。若找到有效匹配，则输出匹配对；否则，输出字面量。同时，将当前序列及其索引更新到字典中，供后续的匹配查找使用。
    

### 3.1.2 系统架构设计 (优化后)

为实现极致的吞吐性能，本设计采用了一种深度流水线化的单遍处理架构，旨在达成每个时钟周期处理一个输入字节的**II=1**目标。该架构通过最大化并行度来消除数据依赖和计算瓶颈。

- **顶层架构：**
    - **Stage 0：滑动窗口与哈希计算**
        
        负责从输入流中读取字节，更新定长的`present_window`滑动窗口，并为窗口内的当前序列并行计算哈希地址。
        
    - **Stage 1：字典读写与并行匹配**
        
        此为流水线的核心。根据哈希地址，在一个周期内完成字典的读取、匹配比较、最佳匹配选择，并将当前窗口内容写回字典。这是性能优化的关键所在。
        
    - **Stage 2：输出编码与尾部融合处理**
        
        根据 Stage 1 的匹配结果（字面量或<长度, 偏移量>对），生成符合格式的32位输出字。同时，该阶段集成了高效的尾部数据处理逻辑，避免了额外的处理循环。
        
- **核心计算模块设计：**
    1. **模块A：哈希与字典管理单元**
        
        该模块负责哈希地址生成以及高效的字典存取。相较于原版设计在每次压缩开始前需要一个独立的循环来清空字典，优化后的设计引入了**Epoch失效化机制**。
        
        - **要点：**
            - **Epoch机制**：增加一个与字典（`dict`）同样大小的`tag` RAM。每次启动压缩任务时，全局Epoch值`curEpoch`递增。读字典时，比较`tag`中存储的Epoch与`curEpoch`是否一致。若不一致，则视该字典条目为无效。写字典时，则同时更新数据和`tag`。此方法**以空间换时间**，将原版设计中与字典大小成正比的初始化延迟（O(N)）降至常数时间（O(1)）。
            - **哈希计算优化**：采用两级异或树结构来计算哈希，降低了关键路径上单个逻辑单元的扇出，有助于时序收敛。
    2. **模块B：并行匹配与选择核心**
        
        这是本设计中性能提升最显著的模块。它将原版设计中串行的、逐字节的匹配长度比较逻辑，重构为**并行**的组合逻辑电路。
        
        - **要点：**
            - **并行前缀匹配**：原版通过一个带有`done`标志位的循环来逐字节比较，存在循环携带依赖（Loop-carried Dependency），无法实现II=1。优化设计中，通过`#pragma HLS UNROLL`将`MATCH_LEVEL`个候选条目全部展开，并对每个条目的`MATCH_LEN`个字节进行**并行比较**，生成一个相等向量`eq`。随后，通过与操作构造前缀“全1”向量`run`，并利用加法树在一个周期内计算出匹配长度。这彻底打破了数据依赖，是实现II=1的关键。
            - **窄位宽算术**：在计算偏移量时，通过逻辑分析可知其最大值远小于32位。优化设计将偏移量计算中的减法操作数从`ap_uint<24>`收窄至`ap_uint<17>`，减少了算术逻辑的资源消耗和路径延迟。
            - **依赖解除**：通过`#pragma HLS dependence variable=dict inter false`指令，明确告知HLS工具字典的读写不存在跨循环迭代的真实依赖，允许其进行更激进的流水线调度。
    3. **模块C：循环融合与输出单元**
        
        该模块负责数据输出以及对整体流程的简化。优化设计将原版中分离的**预热、主处理和多个尾部处理循环**进行了融合。
        
        - **要点**
            - **预热并入**：将填充滑动窗口的预热阶段逻辑，融合进了主处理循环的起始部分，通过一个计数器`valid`来控制匹配逻辑的启动，简化了顶层控制流。
            - **尾部融合**：原版设计使用两个独立的循环（`lz_compress_leftover`和`lz_left_bytes`）来处理窗口内的剩余字节和输入流末尾的字节。优化设计将这两个过程合并为一个名为`tail_fused`的单一循环，减少了循环切换的开销。

## 3.2 **优化方向选择与原理**

### 3.2.1 优化目标分析

根据对赛题初始代码的综合结果P&R的分析，我们识别出两大根本性性能瓶颈：其一，核心匹配逻辑采用串行循环，存在循环携带依赖，导致主处理循环的II远大于1。其二，每次压缩前 O(N) 复杂度的字典清空操作，带来了不可忽视的启动延迟，在频繁调用场景下性能损失巨大。据此，我们把本设计的优化目标定为：

- 实现单周期吞吐率 (II=1）
- 消除初始化延迟
- 提升时钟频率 (Fmax)

### 3.2.2 具体优化策略与 HLS 指令应用

针对上述瓶颈，我进行了深入的架构性重构。优化的核心思想是：**通过改变数据的存储、流动与计算方式，从根本上消除性能瓶颈。**

1. **存储优化**
    - **Epoch失效化， O(1) 字典重置**
        - **问题**：原始设计在每次压缩任务开始前，都需要一个独立的 `dict_flush` 循环来物理清空整个字典。
        - **原理与实现**：为消除此延迟，我们引入了**Epoch失效化机制**。该机制通过增加一个 `tag` 存储和 `curEpoch` 计数器，将物理清除转变为逻辑标记，实现了 O(1) 的“即时”重置。
            - **原始代码**：
                
                ```jsx
                *// Initialization of Dictionary*
                dict_flush:
                    for (int i = 0; i < LZ_DICT_SIZE; i++) {
                #pragma HLS PIPELINE II = 1
                #pragma HLS UNROLL FACTOR = 2
                        dict[i] = resetValue;
                    }
                ```
                
            - **优化代码**：
                
                ```jsx
                *// 字典 + 槽位 epoch 标签（T2P BRAM，读写同拍）*static ap_uint<8>  tag[LZ_DICT_SIZE];
                #pragma HLS BIND_STORAGE variable=tag  type=RAM_T2P impl=BRAM
                static ap_uint<8>  curEpoch = 0;
                curEpoch++; *// O(1) 复杂度的“清空”操作// ... 在主循环内 ...// 字典读 + 按需失效*
                ap_uint<8>  t = tag[hash];
                uintDictV_t effectiveRead = (t == curEpoch) ? dictReadValue : resetValue;
                
                *// 写回：...同时更新 epoch 标签*
                tag[hash]  = curEpoch;
                ```
                
    
    ---
    
2. **流水线与并行化优化**
    - **并行前缀匹配**
        - **问题**：原始设计中计算匹配长度的逻辑是一个串行循环，它逐字节比较并依赖一个 `done` 标志位来提前退出。
        - **原理与实现**：对该算法进行了彻底的硬件化重构，将其从一个时域上的迭代过程，转变为一个完全并行的组合逻辑电路，从而在一个时钟周期内完成计算。
    - **循环融合：简化控制流与减少流水线开销**
        - **问题**：原始设计的控制流被分割为多个独立的循环（预热、主处理、两种尾部处理），增加了复杂性，并可能在循环切换时引入气泡。
        - **原理与实现**：我们将这些分离的阶段逻辑，融合进了统一的、连续的数据通路中，从而简化了状态机，提高了流水线效率。
            - **原始代码**：存在 `lz_compress`、`lz_compress_leftover`、`lz_left_bytes` 等多个独立的循环体。
            - **优化代码**：
                
                ```jsx
                *// 预热逻辑并入主循环，通过 valid 计数器控制*
                lz_compress:
                   for (uint32_t i = 0; i < main_iters; ++i) {
                       *// ...*bool do_compute = (valid >= (MATCH_LEN - 1));
                       if (valid < MATCH_LEN) valid++;
                
                       if (do_compute) {
                           *// 核心匹配逻辑*
                       }
                *// 尾部融合：将两种尾部处理合并为一个循环*
                tail_fused:
                   for (int t = 0; t < tail_iters; ++t) {
                       *// ...*
                   }
                ```
                
    
    ---
    
3. **关键 HLS 指令应用**
    - `#pragma HLS ARRAY_PARTITION variable=present_window complete`:
        
        > **作用**：将数组 `present_window` 的所有元素映射为独立的寄存器。这消除了 BRAM/LUTRAM 的端口限制。
        > 
    - `#pragma HLS dependence variable=dict inter false`:
        
        > **作用**：主动告知 HLS 工具，可以忽略对 `dict` 数组的跨迭代依赖（即读后写风险）。
        > 

## 3.3 **LLM 辅助优化记录**

详见llm_usage，本报告中选取2个关键的交互记录。

### **使用场景 3：关键架构重构与代码实现**

在确定了核心优化方案后，我们要求模型提供可直接编译和测试的代码，以快速落地“Epoch失效化”架构。

**Prompt设计：**

我们决定采纳方案A（Epoch标记失效化）。请提供一版更改后可编译的代码。要求：

1. 移除`dict_flush`循环。
2. 引入`tag`数组和`curEpoch`计数器，并重构字典的读写逻辑以实现按需失效。
3. 在函数顶部添加版本号和简要功能注释。
4. 请简要分析此更改是否会影响最终的压缩比。

**模型输出摘要**

模型根据指令生成了应用方案A后的代码补丁。模型同时确认，该修改仅改变了字典的初始化方式，并未触及任何匹配算法的核心逻辑，因此压缩比与原始实现完全等价。

**人工审核与采纳情况**

我们直接将模型生成的代码替换到项目中。模型生成的代码在结构上基本正确，但在HLS指令的运用上存在疏漏。初版代码忘记为新增的`tag`数组添加`#pragma HLS dependence variable=tag inter false`指令。这导致HLS工具保守地认为`tag`的读写存在跨迭代依赖，从而将主循环的II（启动间隔）劣化为2。通过代码审查，我定位到这一问题，并手动添加了该指令。

---

### **使用场景 4：增量优化与微架构迭代**

在完成核心架构重构后，我们进入了精细的“抠周期”阶段。我们利用模型进行了一系列小步快跑式的微架构优化。

**Prompt设计：**

（分多轮进行）

1. “Latency已优化到1346。请在此基础上尝试方案C，将预热窗口（`present_window`的初始化）合并入主循环，以消除独立的预热循环开销。”
2. “方案C使Latency降至1345。请继续分析，是否有能够小幅砍掉cycles的方案，例如对尾部处理逻辑的优化。”
3. “我们已采纳尾部融合方案，Latency降至1343。请对`lzBestMatchFilter`和`lzBooster`模块进行类似的尾部融合优化。”

**模型输出摘要**

模型在每一轮都准确理解了我们的增量优化意图，并提供了精确的代码补丁：

- **预热融合**：通过引入`valid`计数器，将窗口预热的逻辑无缝并入`lz_compress`主循环的起始阶段。
- **尾部融合**：将原先分离的`lz_compress_leftover`和`lz_left_bytes`两个循环，合并为一个单一的、逻辑分阶段的`tail_fused`循环。
- **其他模块融合**：为`lzBestMatchFilter`和`lzBooster`提供了类似的尾部处理融合代码。

**人工审核与采纳情况**

我们逐一采纳了模型提出的循环融合方案。在审查其生成的`tail_fused`（尾部融合）循环时，发现了llm生成的尾部循环在处理边界条件时，错误地将`present_window`的最后一个字节输出了两次，同时遗漏了从输入流中读取的第一个`LEFT_BYTES`字节。我随即重写了`tail_fused`循环的内部逻辑，通过 `if (t < (MATCH_LEN - 1))` 条件判断，精确地划分了“从窗口输出”和“从输入流输出”两个阶段，确保了数据流的正确衔接。

## **3.4 优化前后性能与资源对比报告**

### 3.4.1 综合结果对比 (资源与性能表格)

- **资源使用对比（来自export_impl.rpt）**
    
    
    | **资源类型** | **优化前** | **优化后** | **改善幅度** | **利用率(优化前)** | **利用率(优化后)** |
    | --- | --- | --- | --- | --- | --- |
    | BRAM | 106 | 108 | +1.89% | 37.86% | 38.57% |
    | DSP | 0 | 0 | N/A | 0.00% | 0.00% |
    | LUT | 2889 | 2376 | -17.76% | 5.43% | 4.47% |
    | FF | 2440 | 2237 | -8.32% | 2.29% | 2.10% |
- **性能指标对比**
    
    
    | **性能指标** | **优化前** | **优化后** | **改善幅度** |
    | --- | --- | --- | --- |
    | 延迟(Latency) | 3390 | 1344 | -60.35% |
    | EstimatedClockPeriod(ns) | 13.220 | 13.128 | -0.70% |

### 3.4.2 详细分析 (解释数据变化原因)

- **资源优化分析**
    
    **BRAM优化效果：**
    
    该增长源于为实现 O(1) 初始化而引入的 **Epoch 失效化机制**。该机制增加了一个与字典同样大小的 `tag` 数组，用于存储版本信息。
    
    **逻辑资源优化效果：**
    
    LUT 和 FF 资源均有下降（分别减少17.8%和8.3%）。主要原因在于，尽管“并行前缀匹配”重构展开了大量逻辑，但它用纯组合逻辑的数据通路，替代了原版设计中带有复杂控制流的串行循环。
    
- **性能优化分析**
    
    **流水线效率提升：**
    
    流水线效率得到了大幅提升。通过将匹配长度计算从串行循环重构为并行组合逻辑，我们消除了循环携带依赖。
    
    **延迟优化效果：**
    
    端到端延迟降低了 60.4%，效果显著。这主要归功于两点：首先，O(1) 的 **Epoch 机制**彻底消除了原版设计中高昂的字典初始化延迟；其次，主循环 **II=1** 的实现，使得处理相同数量输入数据所需的总时钟周期数大幅减少。
    

### 3.4.3 正确性验证

- **仿真配置：**
    
    采用赛题官方给出的测试用例
    
- **仿真结果：**
    
    功能正确性：✅ 通过 
    
- **仿真结果：**
    - 时序正确性：✅ 通过
    - 接口兼容性：✅ 通过
    - 性能匹配度：[100%]

## **3.5 本算子遇到的问题与解决方案**

### **3.5.1 遇到的主要问题**

1. 启动开销大
2. 关键路径深，拍内存在串行链。

---

### **3.5.2 采用的解决方案**

1. Epoch 失效化，引入 `tag[] + curEpoch`，读时按需失效、写时打标，删除 `dict_flush`（≈ −2048 cycles）。
2. 预热/尾部合并

# 4. Cholesky **算子优化设计**

## 4.1 **设计原理和功能**

### 4.1.1 算法原理

**Cholesky 分解**将一个埃尔米特正定矩阵 `A` 分解为一个下三角矩阵 `L` 与其共轭转置 `L*` 的乘积，即  $A = LL^*$。该算法按列迭代计算 `L` 矩阵的元素。

- **对角线元素计算**
    
    第 `j` 列的对角线元素  $L_{j,j}$ 由 `A` 的对角元素 `A(j,j)` 减去该行已计算出的 `L` 元素模平方和后开方得到：
    
    $L_{j,j} = \sqrt{A_{j,j} - \sum_{k=0}^{j-1} |L_{j,k}|^2}$
    
- **非对角线元素计算**
    
    同一列的非对角线元素 $L_{i,j}$ (`i > j`) 则由 `A` 的对应元素 `A(i,j)` 减去一个向量点积后，再除以该列的对角元素得到：
    
    $L_{i,j} = \frac{1}{L_{j,j}} \left( A_{i,j} - \sum_{k=0}^{j-1} L_{i,k} \overline{L_{j,k}} \right)$
    

### 4.1.2 系统架构设计 (优化后)

为在 FPGA 上实现极致性能，本设计针对不同矩阵规模采用**双路径架构**。核心优化集中在小尺寸矩阵（$RowsColsA \le 8$）路径，该路径将算法完全映射为深度流水化的并行处理单元；对于大尺寸矩阵，则回退至基于 BRAM 的通用架构。

- **顶层架构：**
    - **Stage 0：列数据预取与广播**
        
        在处理第 `j` 列前，从核心存储中预取计算所需的历史 `L` 值 $L_{j,k}$，并预计算用于 3 乘法复数优化的分量，广播给后续处理单元。
        
    - **Stage 1：对角线计算**
        
        一个专用的计算核，负责累加模平方和 $\Sigma|L(j,k)|^2$，并调用优化后的 `rsqrt` 模块计算对角元素 $L_{j,j}$ 及其倒数。
        
    - **Stage 2：列元素并行计算**
        
        由 `P_PAR` 个处理单元组成的阵列，并行计算当前列的所有非对角元素 $L_{i,j}$。
        
    - **Stage 3：结果写回**
        
        将 Stage 1 和 Stage 2 计算出的新 `L` 元素并行地写回核心存储，为下一列的计算做准备。
        
- **核心计算模块设计：**
    1. **模块 A ：L-Bank 核心存储**
        
        此模块将小矩阵 `L` 的存储从原始设计基于 BRAM 的一维化数组 `L_internal`，优化为一个 $RowsColsA \le 8$ 的全分区寄存器阵列 **`L_bank`**。
        
        - **要点：**
            - **存储优化：** 使用 `#pragma HLS ARRAY_PARTITION complete` 将 `L_bank` 在物理上实现为独立的寄存器。
            - **并行访问：** 为所有计算单元提供单周期的、无冲突的并行读写能力，是实现 `II=1` 流水线和大规模并行计算的前提。
    2. **模块 B ：对角线与列元素并行计算核**
        
        该模块将对角线计算和列元素计算流水化、并行化。
        
        - **要点：**
            - **并行架构：** 通过 `P_PAR` (并行度) 和 `UF` (展开因子) 参数，结合 `#pragma HLS UNROLL`，实例化出多个 PE，同时处理一列中的多个元素。
            - **算术优化：**
                - **求逆开方**：采用**牛顿迭代法**实现的 `cholesky_rsqrt` 替代了高延迟的 `sqrt` 和 `div` 组合，降低对角线计算的延迟。
                - **复数乘法**：采用 **3 乘法** 结构 (`m1=a*c, m2=b*d, m3=(a+b)*(c-d)`) 替代标准的 4 乘法，降低了组合逻辑深度。
                - **模平方**：对角线计算中的 `|v|²` 被显式分解为 `vr*vr + vi*vi`，避免了复数乘法器的调用，有利于提升Fmax。
            - **资源绑定：** 通过 `#pragma HLS BIND_OP` 将关键乘法绑定到专用 DSP，确保了稳定的 `II=1` 。

## 4.2 **优化方向选择与原理**

### 4.2.1 优化目标分析

根据对赛题初始代码的综合结果P&R的分析，其性能瓶颈主要体现在以下几个方面：1) 核心算术单元延迟高；2) 存储访问模式受限，基于 BRAM 的实现限制了并行读写能力；3) 串行化的计算流程，内外层循环缺乏并行处理机制。据此，我们把本设计的优化目标定为：

- 降低核心算术单元延
- 消除存储访问瓶颈
- 最大化数据级并行
- 提升系统Fmax

### 4.2.2 具体优化策略与 HLS 指令应用

为实现上述目标，我们对小尺寸矩阵（$RowsColsA ≤ 8$）的处理路径进行了根本性的**架构重构**。这一重构围绕存储、流水线和并行化三个维度展开。

1. **存储优化**
    - **存储架构重构：从一维化 BRAM 到全分区L-Bank**
        - **问题**：原始设计将下三角矩阵 `L` 存储在一维数组 `L_internal` 中，并通过 `row_off` 函数动态计算访问地址。这种方式杜绝了对 `L` 矩阵进行大规模并行读写的可能性，是导致整个计算流程串行化的根源。
        - **原理与实现**：对存储系统进行了重构。优化后的设计将 `L` 的存储从一维 BRAM 升级为一个二维的 `L_bank` 寄存器阵列。这一改变的本质是利用 `#pragma HLS ARRAY_PARTITION complete` 指令，将 `L_bank` 彻底分解为 `RowsColsA * RowsColsA` 个独立的寄存器。这使得在任意时刻，硬件都可以单周期地并行访问 `L_bank` 中的任意元素。
            - **原始代码**：
                
                ```jsx
                OutputType L_internal[(RowsColsA * RowsColsA - RowsColsA) / 2];
                *// ... 访问时需要复杂的地址计算 ...*
                L_internal[i_off + k]
                ```
                
            - **优化代码**：
                
                ```jsx
                LOUT_T L_bank[RowsColsA][RowsColsA];
                #pragma HLS ARRAY_PARTITION variable=L_bank dim=0 complete
                *// ... 直接通过行列索引并行访问 ...*
                L_bank[i][k]
                ```
                
    
    ---
    
2. **流水线优化**
    - **高延迟算术单元替换：以牛顿迭代法 `rsqrt` 替代 `sqrt+div`**
        - **问题**：原始 `cholesky_rsqrt` 函数直接调用 `x_sqrt` 和除法器
        - **原理与实现**：我为定点数特化了 `cholesky_rsqrt` 函数，采用数值计算方法进行替代。新实现采用可以被高效流水化的“rsqrt + 1 次牛顿迭代”的策略。
            - **原始代码**：
                
                ```jsx
                sqrt_res = x_sqrt(x);
                res = one / sqrt_res_cast;
                ```
                
            - **优化代码**：
                
                ```jsx
                *//1 次牛顿迭代（定点域），II=1 流水；不形成长链*
                work_t term   = onept5 - half * xin * y_sq;
                y             = y * term;
                ```
                
    - **降低组合逻辑深度：以 3 乘法结构优化复数点积**
        - **问题**：在 `t_loop_small` 循环中，核心计算是复数乘法 `li * hls::x_conj(lj)`。标准的复数乘法需要 4 个实数乘法器和 2 个加/减法器。
        - **原理与实现**：采纳了 Karatsuba 算法的思想，将复数乘法重构为 3 乘法 形式，
            - **原始代码 ：**
                
                ```jsx
                prod = -L_internal[i_off + k] * hls::x_conj(L_internal[j_off + k]);
                ```
                
            - **优化代码 (显式分解)**：
                
                ```jsx
                *// li = a+bi, conj(lj)=c - di；3乘法*
                SCALAR_T m1  = a * c;
                SCALAR_T m2  = b * d;
                SCALAR_T apb = a + b;
                SCALAR_T m3  = apb * (c - d); *// c-d 已被预计算*
                SCALAR_T t_real = m1 + m2;
                SCALAR_T t_imag = (m3 - m1) + m2;
                ```
                
    
    ---
    
3. **并行化优化**
    - **数据级并行：构建列元素并行计算阵列 (PE Array)**
        - **问题**：原始设计的 `col_loop` 循环是完全串行的。对于给定的列 `j`，它依次计算 `L(j+1, j)`, `L(j+2, j)`, ..., `L(N-1, j)`。
        - **原理与实现**通过引入 `pe_loop_small` 循环并应用 `#pragma HLS UNROLL`，将串行计算重构为一个并行处理阵列。`#pragma HLS UNROLL` 指令将 `pe_loop_small` 循环体在硬件中复制 `P_PAR` 份，形成了 `P_PAR` 个并行的处理单元（PE）。这些 PE 在同一时钟周期内，同时从 `L-Bank` 读取各自所需的数据，并行地为 `P_PAR` 个不同的行 `i` 计算 `L(i,j)` 的值。
    
    ---
    
4. **关键 HLS 指令应用**
    - `#pragma HLS ARRAY_PARTITION complete`
        
        > 目的：将 `L_bank` 存储器分解为独立寄存器，为所有并行化提供了必要的无冲突数据通路。
        > 
    - `#pragma HLS UNROLL`
        
        > 用于实例化 `pe_loop_small`，将循环迭代在空间上展开为并行的硬件处理单元。
        > 

## 4.3 **LLM 辅助优化记录**

详见llm_usage，本报告中选取2个关键的交互记录。

---

### **使用场景 3：关键代码实现（方案A）**

在确定了核心优化方案后，我们要求模型提供可直接编译和测试的代码，以快速落地“按列并行推进“。

**Prompt设计：**

我们决定采纳方案A。请提供一版更改后可编译的代码。要求：

1. 重构核心循环结构
2. 解决访存冲突
3. 设计广播机制
4. 在函数顶部添加版本号和简要功能注释。
5. 请简要分析此更改是否会影响最终的压缩比。

**模型输出摘要**

模型根据指令生成了应用方案A后的代码补丁。同时模型在分析部分指出，该策略会使 BRAM 资源消耗量与并行度 `P_PAR` 成正比，是一种典型的“以面积换性能”设计，是确保 `II=1` 稳定流水线的必要代价。

**人工审核与采纳情况**

在进行 HLS 综合审查后，我发现了一个隐藏的性能缺陷：所有并行单元在启动时都会争抢访问顶层的单端口输入数组 `A`，导致并行设计因访存冲突而失效，启动间隔（II）远大于 1。为此，我指导模型进行了关键修正，即在并行计算前增加一个数据预取阶段，将所需数据从 `A` 提前加载到一个完全分区的本地寄存器缓存 `anchor` 中。这一干预彻底解决了输入瓶颈，使并行循环成功达到 `II=1` 。

---

### **使用场景 4：实现 K 维向量化 (方案 D)**

**Prompt设计：**

当前 Latency 为 3735 周期。请在当前 vA-1.1 版本的基础上，继续实施方案 D，即对 PE 内部的点积计算（k 循环）进行向量化，以进一步降低延迟。

**模型输出摘要**

模型生成了 vA-2.0 版本，在上一版基础上增加了 k 维向量化：

1. 引入 `UF` (Unroll Factor) 参数，将内层点积循环改造为“外层以步长 `UF` 流水，内层 `UNROLL`”的结构，实现了单拍内处理 `UF` 个元素的向量化计算。
2. 模型正确地推断出，`UF` 的引入会使每个 PE 在一拍内需要 `UF` 个读端口。因此，它自动将存储副本数量从 `P_PAR` 扩展到了 `R_REP = P_PAR * UF` 份，并为每个 unroll 的 lane 分配了专属的存储副本索引 `rep_idx = p * UF + u`，解决了访存冲突。

**人工审核与采纳情况**

采纳补丁，Cosim一次性PASS。

## **4.4 优化前后性能与资源对比报告**

### 4.4.1 综合结果对比 (资源与性能表格)

- **资源使用对比（来自export_impl.rpt）**
    
    
    | **资源类型** | **优化前** | **优化后** | **改善幅度** | **利用率(优化前)** | **利用率(优化后)** |
    | --- | --- | --- | --- | --- | --- |
    | BRAM | 0 | 2 | +2块 | 0.00% | 0.71% |
    | DSP | 14 | 45 | +221.4% | 6.36% | 20.45% |
    | LUT | 4682 | 2864 | -38.8% | 8.80% | 5.38% |
    | FF | 6135 | 3226 | -47.4% | 5.77% | 3.03% |
- **性能指标对比**
    
    
    | **性能指标** | **优化前** | **优化后** | **改善幅度** |
    | --- | --- | --- | --- |
    | 延迟(Latency) | 4919 | 1807 | -63.3% |
    | EstimatedClockPeriod(ns) | 6.276 | 6.055 | -3.5% |

### 4.4.2 详细分析 (解释数据变化原因)

- **资源优化分析**
    
    **BRAM 使用**：BRAM 的增加是为大矩阵路径设计的显式存储映射。
    
    **DSP 使用**：DSP 的激增主要源于大规模并行化（`UNROLL` 创建的 PE 阵列）和确保 `II=1` 稳定性的资源绑定（`BIND_OP`）。
    
    **LUT & FF使用**：LUT 和 FF 的显著减少得益于架构简化。
    
- **性能优化分析**
    
    **吞吐率提升分析**：吞吐率的上升源于**数据级并行**。优化后的设计每个时钟周期能并行处理 `P_PAR` 个元素，而原始设计只能串行处理一个，有效工作效率提升了 `P_PAR` 倍。
    
    **延迟优化效果**：延迟的大幅降低主要来自两方面：1) **并行计算**显著减少了完成一列所需的串行循环次数；2) **低延迟 `rsqrt` 核**缩短了对角线计算的关键路径，降低了整体流水线深度。
    

### 4.4.3 正确性验证

- **仿真配置：**
    
    采用赛题官方给出的测试用例
    
- **仿真结果：**
    
    功能正确性：✅ 通过 
    
- **仿真结果：**
    - 时序正确性：✅ 通过
    - 接口兼容性：✅ 通过
    - 性能匹配度：[100%]

## **4.5 本算子遇到的问题与解决方案**

### **4.5.1 遇到的主要问题**

1. 总周期偏大
2. 关键路径偏深（Estimated 高）
3. 偶发背压导致隐形气泡

---

### **4.5.2 采用的解决方案**

1. 架构重排
2. k 向量化与分块流水
3. 平方根/倒数路径压缩
4. 复数定点优化。
5. 算子内联与资源绑定

---

# 5. 创新点总结

## 5.1 技术创新点

我们的主要创新点是从硬件角度出发，重新设计了算法的实现结构，而不仅仅是添加Pragma。

1. **重新设计算法结构，使其适合硬件并行**
    - **SHA-256**：把原来一个大循环拆分成多个小模块，用流水线串起来，再复制多份并行处理。
    - **LZ4**：把原来逐个字节比较的串行操作，改成用组合逻辑一次性算出匹配长度。
    - **Cholesky**：把原来存在BRAM里的一维数组，改成一个全分区的二维寄存器阵列，让所有计算单元都能同时读写，没有冲突。
2. **针对关键瓶颈的改动**
    - **消除LZ4启动延迟**：我们进行了“Epoch失效”机制优化。不清空字典，而是给每个字典项加一个“版本号”，启动时只更新全局版本号。这把原来O(N)的清空操作变成了O(1)。
    - **压缩Cholesky计算时间**：我们用“牛顿迭代法”实现开方倒数，替代了原来很慢的“开方+除法”组合，缩短了最长的计算路径。
3. **采用更高效的硬件实现**
    - **SHA-256**：用**循环缓冲**结构来更新消息，替代了原来需要移动大量数据的数组。
    - **Cholesky**：用**3乘法结构**实现复数乘法，替代了标准的4乘法，节省了DSP。
    - **LZ4**：把多个处理不同阶段的小循环合并成一个，简化控制逻辑，减少气泡。

## 5.2 LLM辅助方法创新

在本项目中，我探索并总结出了一套与LLM高效协同工作的具体方法，旨在提高优化效率和成功率。

1. **策略生成与专家筛选结合**
    
    我首先让LLM针对一个优化目标，生成尽可能多的（例如6个以上）不同策略并按其认为的优先级排序。然后，利用自己的工程经验，从这些选项中快速筛选出2-3个最可能成功的方案进行尝试。这种“广撒网、精捕捞”的方式，结合了LLM的发散性思维和人的聚焦判断，效率远高于自己从零开始思考或逐一尝试LLM的建议。
    
2. **利用“负反馈”为LLM设定边界**
    
    我将自己在HLS开发中走过的弯路（例如某些导致时序恶化或资源激增的“负优化”经验），总结成明确的“禁止项”或“避坑指南”。在向LLM提问时，我们会将这些“黑线”作为预设提示词，提前告知LLM需要规避的方向。这能有效引导LLM避免给出我们已知的无效或有害建议。
    
3. **预设严格的工程限制**
    
    在要求LLM生成代码或方案时，我们不会给出模糊的需求，而是会附上非常具体的工程限制，例如：“II必须为1”、“这段代码必须在Y个周期内完成”。这种目标驱动的提问方式，迫使LLM在严格的约束下进行思考，其输出的方案也因此更贴近实际工程需求，减少了大量的后期修改工作。
    

# 6. 结论与展望

## 6.1 项目总结

本项目成功完成了对 Vitis Libraries 提供的 SHA-256、LZ4 Compress 和 Cholesky 三个 L1 级别算子的深度硬件优化。项目的核心优化思想是以硬件思维驱动的算法级架构重构。我们针对每个算子的独特瓶颈，从数据通路、存储结构和计算模式等根本层面进行了重新设计，使其软件实现高效地映射为高性能、高并行的硬件逻辑。

在整个开发流程中，我们还形成了一套与 LLM 高效协同的工作方法，通过“策略生成与专家筛选”、“负反馈边界设定”和“严格工程限制”等技巧，显著提升了优化迭代的效率与成功率。

## 6.2 性能达成度

根据竞赛评分标准，我们以 **`预估时钟周期 × Co-sim 延迟`** 的乘积作为最终执行时间，来衡量优化效果。本项目所有算子均取得了显著的性能提升，完全达成了设计目标。具体数据如下表所示：

| **算子**  | **优化前执行时间 (ns)** | **优化后执行时间 (ns)** | **性能提升幅度** |
| --- | --- | --- | --- |
| **SHA-256** | 10,421.5 | 5,798.1 | **44.4%** |
| **LZ4 Compress** | 44,815.8 | 17,644.0 | **60.6%** |
| **Cholesky** | 30,870.7 | 10,941.4 | **64.6%** |

## 6.3 后续改进方向

当前设计仍存在进一步探索和优化的空间：

1. **参数化与可伸缩性设计**：
    
    当前 SHA-256 的并行通道（LANE）数量和 Cholesky 的 PE 阵列大小（P_PAR）是编译时固定的。未来可将其改造为 C++ 模板参数。
    
2. **混合架构与动态调度**：
    
    目前的 Cholesky 算子针对小矩阵路径进行了极致优化。可以设计一个顶层动态调度器，根据输入矩阵的尺寸，自动选择调用高度优化的“小矩阵核心”或资源占用更低的“通用BRAM核心”，以实现对不同负载的自适应。
    
3. **系统级集成与验证**：
    
    当前优化主要在 HLS Co-simulation 层面进行验证。下一步可在 PYNQ-Z2 平台上进行实际的软硬件协同验证，考察在真实内存带宽和系统总线负载下的性能表现。
    

---

# 7. 参考文献

[1] AMD-Xilinx. Vitis High-Level Synthesis User Guide (UG1399), v2024.2, 2024.